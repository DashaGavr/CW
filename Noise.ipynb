{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Noise.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOdJLn8/ilxzKTAjNhCSk8m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ZuZTCMxQDwVA","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSb7iXU9Ddxq","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from tensorflow.keras import regularizers\n","from keras import backend as K\n","import tensorflow as tf\n","\n","class SmallVGGNet:\n","\t@staticmethod\n","\tdef build(width, height, depth, classes):\n","\n","\t\tmodel = Sequential()\n","\n","\t\tinputShape = (height, width, depth)\n","\t\tchanDim = -1\n","\n","\t\t# (CONV => RELU) * 2 => POOL layer set\n","\t\tmodel.add(BatchNormalization(input_shape=inputShape, axis=chanDim))\n","\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\t\t\t\t#, kernel_regularizer=tf.keras.regularizers.l2(l=0.01)\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n","\t\tmodel.add(Dropout(0.2))\n","\n","\t\t# (CONV => RELU) * 2 => POOL layer set\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\t\t\t\t#\t, kernel_regularizer=tf.keras.regularizers.l2(l=0.01) \n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\t\n","\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\t\t\t\t#, kernel_regularizer=tf.keras.regularizers.l2(l=0.01)\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Dropout(0.25))\n","\t\tmodel.add(GlobalAveragePooling2D(data_format='channels_last'))\n","\n","\t\tmodel.add(BatchNormalization(axis=chanDim))\n","\t\tmodel.add(Dense(256))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\tmodel.add(Dropout(0.5))\n","\t\t\n","\t\tmodel.add(Dense(16))\t\t\n","\t\tmodel.add(Activation(\"relu\"))\n","\n","\t\tmodel.add(Dense(classes))\n","\t\tmodel.add(Activation(\"relu\"))\n","\t\t# return the constructed network architecture\n","\t\treturn model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WtxzELEVDpci","colab_type":"code","outputId":"6bc758a3-e6d8-4c93-c9fa-22215694e706","executionInfo":{"status":"ok","timestamp":1589043158560,"user_tz":-180,"elapsed":946914,"user":{"displayName":"Dasha Gavrilova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhyseUT5QcJQqE_C_D00jrQd9g0BLg7nSOAF7YACg=s64","userId":"17021977493992781937"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","import sys\n","matplotlib.use(\"Agg\")\n","# import the necessary packages\n","sys.path.insert(1, \"/gdrive/My Drive/App\")\n","import sys\n","import skimage\n","from skimage import img_as_float\n","from numpy import genfromtxt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","import pandas as pd\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers, Model, callbacks\n","from keras.optimizers import SGD, RMSprop, Adam\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import random\n","from keras.applications import ResNet50\n","import pickle\n","import cv2\n","import keras.models \n","import os\n","\n","INIT_LR = 3e-3\n","EPOCHS = 50\n","BS = 32\n","SIZE = 64\n","SIZECUT = 32\n","\n","# initialize the data and labels\n","def load_attributes(inputPath):\n","  cols = [\"ringing\", \"defocus\",\"noise\"]\n","  col = [\"noise\"]\n","  col2 =[\"ringing\"]\n","  df = pd.read_csv(inputPath, sep=\",\",  usecols=col)\n","  return df\n","\n","def process_image(im):\n","\tw = im[im.shape[0]//2 - SIZECUT:im.shape[0]//2 + SIZECUT, im.shape[1]//2 - SIZECUT:im.shape[1]//2 + SIZECUT]\n","\treturn w\n","\n","print(\"[INFO] loading images...\")\n","data = []\n","attrib = []\n","# grab the image paths and randomly shuffle them\n","imagePaths = sorted(list(paths.list_images(\"/gdrive/My Drive/App/database\")))\n","i = 0\n","# loop over the input images\n","for imagePath in imagePaths:\n","  if i == 5500:\n","    break\n","  image = cv2.imread(imagePath)  \n","  img = process_image(image)\n","  data.append(img) \n","\n","# scale the raw pixel intensities to the range [0, 1]\n","data = np.array(data, dtype='float32')/ 255\n","\n","print(\"[INFO] loading attributes...\")\n","attrib = load_attributes(\"/gdrive/My Drive/App/Param.csv\")\n","attrib = attrib[:5500]\n","\n","print(\"[INFO] split the data...\")\n","(trainX, testX, trainY, testY) = train_test_split(data,\n","\tattrib, test_size=0.25, random_state=42)\n","\n","optA = Adam(lr=INIT_LR)\n","\n","model = SmallVGGNet.build(width=SIZE, height=SIZE, depth=3, classes=1)\n","model.compile(loss=\"mse\", optimizer=optA,\n","\tmetrics=[\"accuracy\"])\n","'''\n","filepath = \"/gdrive/My Drive/App/Model.h5\"\n","checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]\n","'''\n","print(\"[INFO] training network...\")\n","H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=EPOCHS, batch_size=BS)   #, callbacks=callbacks_list\n","\n","N = np.arange(0, EPOCHS)\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","#plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n","plt.title(\"Training Loss\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.savefig(\"/gdrive/My Drive/App/N/Noise_train.png\")\n","\n","from keras.utils import plot_model\n","plot_model(model, to_file='/gdrive/My Drive/App/N/CnnN.png', show_shapes=True)\n","\n","# evaluate the network\n","print(\"[INFO] evaluating network...\")\n","result = model.evaluate(testX, testY, batch_size=BS)\n","\n","print('test loss, test acc:', result)\n","predictions = model.predict(testX, batch_size=BS)\n","\n","print(\"[INFO] serializing network...\")\n","model.save(\"/gdrive/My Drive/App/N/CnnN_last.h5\")\n","\n","print(\"MSE  (testY, predictions)\")\n","print(mean_squared_error(testY, predictions, squared=False))\n","\n","'''\n","print(predictions[:10])\n","print(testY[:10])\n","predictions2 = model.predict(trainX[:10], batch_size=BS)\n","print(predictions2[:10], end='\\t')\n","print(trainY[:10])\n","'''\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] loading images...\n"],"name":"stdout"}]}]}